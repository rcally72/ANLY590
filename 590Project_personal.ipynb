{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5fl51mcQfE0"
   },
   "source": [
    "ANLY 590 \\\n",
    "Final Project \\\n",
    "December 16, 2020 \\\n",
    "Random Forrest: Chris Fiaschetti, Ryan Callahan, Ruchikaa Kanar & Masha Gubenko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8L89NdpRARX"
   },
   "source": [
    "Github repo: https://github.com/mgubenko/590Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdH-0VwUQSGK",
    "outputId": "4e91318e-6f05-4fb1-b229-5420dd2f3969"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.layers as tfkl\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "#from google.colab import drive\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "#import cache_magic\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from os import makedirs\n",
    "from tensorflow.keras.models import load_model\n",
    "from numpy import dstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIHE0VC0QWPW",
    "outputId": "e3b86984-95aa-4314-8b14-c929230f0d6d"
   },
   "outputs": [],
   "source": [
    "#drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "weS_LoQLEiNA",
    "outputId": "601ba9d6-7ed9-4ed3-beb6-d22baa9855a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n02097658-silky_terrier\n",
      "n02092002-Scottish_deerhound\n",
      "n02099849-Chesapeake_Bay_retriever\n",
      "n02091244-Ibizan_hound\n",
      "n02095314-wire-haired_fox_terrier\n",
      "n02091831-Saluki\n",
      "n02102318-cocker_spaniel\n",
      "n02104365-schipperke\n",
      "n02090622-borzoi\n",
      "n02113023-Pembroke\n",
      "n02105505-komondor\n",
      "n02093256-Staffordshire_bullterrier\n",
      "n02113799-standard_poodle\n",
      "n02109961-Eskimo_dog\n",
      "n02089973-English_foxhound\n",
      "n02099601-golden_retriever\n",
      "n02095889-Sealyham_terrier\n",
      "n02085782-Japanese_spaniel\n",
      "n02097047-miniature_schnauzer\n",
      "n02110063-malamute\n",
      "n02105162-malinois\n",
      "n02086079-Pekinese\n",
      "n02097130-giant_schnauzer\n",
      "n02113978-Mexican_hairless\n",
      "n02107142-Doberman\n",
      "n02097209-standard_schnauzer\n",
      "n02115913-dhole\n",
      "n02106662-German_shepherd\n",
      "n02106382-Bouvier_des_Flandres\n",
      "n02110185-Siberian_husky\n",
      "n02094258-Norwich_terrier\n",
      "n02093991-Irish_terrier\n",
      "n02094114-Norfolk_terrier\n",
      "n02109525-Saint_Bernard\n",
      "n02093754-Border_terrier\n",
      "n02105251-briard\n",
      "n02108551-Tibetan_mastiff\n",
      "n02108422-bull_mastiff\n",
      "n02085936-Maltese_dog\n",
      "n02093859-Kerry_blue_terrier\n",
      "n02104029-kuvasz\n",
      "n02107574-Greater_Swiss_Mountain_dog\n",
      "n02095570-Lakeland_terrier\n",
      "n02086646-Blenheim_spaniel\n",
      "n02088238-basset\n",
      "n02098286-West_Highland_white_terrier\n",
      "n02085620-Chihuahua\n",
      "n02106166-Border_collie\n",
      "n02090379-redbone\n",
      "n02090721-Irish_wolfhound\n",
      "n02088632-bluetick\n",
      "n02113712-miniature_poodle\n",
      "n02113186-Cardigan\n",
      "n02108000-EntleBucher\n",
      "n02091467-Norwegian_elkhound\n",
      "n02100236-German_short-haired_pointer\n",
      "n02107683-Bernese_mountain_dog\n",
      "n02086910-papillon\n",
      "n02097474-Tibetan_terrier\n",
      "n02101006-Gordon_setter\n",
      "n02093428-American_Staffordshire_terrier\n",
      "n02100583-vizsla\n",
      "n02105412-kelpie\n",
      "n02092339-Weimaraner\n",
      "n02107312-miniature_pinscher\n",
      "n02108089-boxer\n",
      "n02112137-chow\n",
      "n02105641-Old_English_sheepdog\n",
      "n02110958-pug\n",
      "n02087394-Rhodesian_ridgeback\n",
      "n02097298-Scotch_terrier\n",
      "n02086240-Shih-Tzu\n",
      "n02110627-affenpinscher\n",
      "n02091134-whippet\n",
      "n02102480-Sussex_spaniel\n",
      "n02091635-otterhound\n",
      "n02099267-flat-coated_retriever\n",
      "n02100735-English_setter\n",
      "n02091032-Italian_greyhound\n",
      "n02099712-Labrador_retriever\n",
      "n02106030-collie\n",
      "n02096177-cairn\n",
      "n02106550-Rottweiler\n",
      "n02096294-Australian_terrier\n",
      "n02087046-toy_terrier\n",
      "n02105855-Shetland_sheepdog\n",
      "n02116738-African_hunting_dog\n",
      "n02111277-Newfoundland\n",
      "n02089867-Walker_hound\n",
      "n02098413-Lhasa\n",
      "n02088364-beagle\n",
      "n02111889-Samoyed\n",
      "n02109047-Great_Dane\n",
      "n02096051-Airedale\n",
      "n02088466-bloodhound\n",
      "n02100877-Irish_setter\n",
      "n02112350-keeshond\n",
      "n02096437-Dandie_Dinmont\n",
      "n02110806-basenji\n",
      "n02093647-Bedlington_terrier\n",
      "n02107908-Appenzeller\n",
      "n02101556-clumber\n",
      "n02113624-toy_poodle\n",
      "n02111500-Great_Pyrenees\n",
      "n02102040-English_springer\n",
      "n02088094-Afghan_hound\n",
      "n02101388-Brittany_spaniel\n",
      "n02102177-Welsh_springer_spaniel\n",
      "n02096585-Boston_bull\n",
      "n02115641-dingo\n",
      "n02098105-soft-coated_wheaten_terrier\n",
      "n02099429-curly-coated_retriever\n",
      "n02108915-French_bulldog\n",
      "n02102973-Irish_water_spaniel\n",
      "n02112018-Pomeranian\n",
      "n02112706-Brabancon_griffon\n",
      "n02094433-Yorkshire_terrier\n",
      "n02105056-groenendael\n",
      "n02111129-Leonberg\n",
      "n02089078-black-and-tan_coonhound\n"
     ]
    }
   ],
   "source": [
    "# Define list that will hold all filenames in sequence\n",
    "file_string_list = []\n",
    "# Define list that will hold arrays of pictures' pixels in sequence\n",
    "data_list = []\n",
    "\n",
    "# Save string that is beginning of every image's filepath\n",
    "dirpath='Images/'\n",
    "# Save list of all folders of dog breeds\n",
    "folders = os.listdir(dirpath)\n",
    "# For each folder (i.e. breed)...\n",
    "for folder in folders:\n",
    "  # Print the folder (i.e. breed) name for tracking purposes\n",
    "  print(folder)\n",
    "  # Save current folder's path as separate string\n",
    "  folderpath = dirpath + folder + '/'\n",
    "  # Save all filenames within current folder to list\n",
    "  file_list = os.listdir(folderpath)\n",
    "  # For each file in this folder...\n",
    "  for filename in file_list:\n",
    "    # Save string that is that file's filepath\n",
    "    filepath = folderpath + filename\n",
    "    # Open the image at that filepath\n",
    "    image = Image.open(filepath)\n",
    "    # Resize image to 200x200 pixels to enable input into neural network\n",
    "    image_resized = image.resize((200,200))\n",
    "    # Convert this resized image to array\n",
    "    data = asarray(image_resized)\n",
    "    # Append this 200x200x3 array to list of all images' arrays\n",
    "    data_list.append(data)\n",
    "\n",
    "    # Save this image's folder and filename as string, which matches the folder-filename combination in the [file list-breed label] array below for later merger (i.e. we will be merging\n",
    "    # image arrays and breed labels using the filenames)\n",
    "    file_string = folder + '/' + filename\n",
    "    # Add this image's filename to list of all filenames, which will be in same sequence as list of all image data\n",
    "    file_string_list.append(file_string)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rM3EduXPqfNg",
    "outputId": "e99b9bf9-668f-49b2-a020-e107ce944be9"
   },
   "outputs": [],
   "source": [
    "#%cache data_l = data_list\n",
    "#%cache file_string_l = file_string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "btA-iaOpQZX7"
   },
   "outputs": [],
   "source": [
    "# Save strings of filepaths for files that contain images' filenames and associated labels\n",
    "file1 = \"file_list.mat\"\n",
    "file2 = \"test_list.mat\"\n",
    "file3 = \"train_list.mat\"\n",
    "## Read in files that contain images' filenames and associated labels\n",
    "mat1 = scipy.io.loadmat(file1)\n",
    "mat2 = scipy.io.loadmat(file2)\n",
    "mat3 = scipy.io.loadmat(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "D9kQP-RCdNOb"
   },
   "outputs": [],
   "source": [
    "# Save list of filenames of images in test set\n",
    "test_filenames_list = mat2['file_list']\n",
    "# Define list that will hold filenames in test set after they've been stripped of their triple-array packing\n",
    "test_filenames = []\n",
    "# For each filename in the test set...\n",
    "for filename in test_filenames_list:\n",
    "  # Strip off array wrapping and add to list of cleaned filenames\n",
    "  test_filenames.append(filename[0][0])\n",
    "# Convert filenames list to DataFrame column for concatenation\n",
    "test_filenames = pd.DataFrame(np.array(test_filenames).reshape((len(test_filenames),1)))\n",
    "# Convert labels list to DataFrame column for concatenation\n",
    "test_labels = pd.DataFrame(mat2['labels'])\n",
    "# Concatenate filenames and labels\n",
    "test_file_label = pd.concat((test_labels,test_filenames),axis=1)\n",
    "# Add column names to concatenated dataframe\n",
    "test_file_label.columns=['label','filename']\n",
    "\n",
    "# Save list of filenames of images in training set\n",
    "train_filenames_list = mat3['file_list']\n",
    "# Define list that will hold filenames in training set after they've been stripped of their triple-array packing\n",
    "train_filenames = []\n",
    "# For each filename in the training set...\n",
    "for filename in train_filenames_list:\n",
    "  # Strip off array wrapping and add to list of cleaned filenames\n",
    "  train_filenames.append(filename[0][0])\n",
    "# Convert filenames list to DataFrame column for concatenation\n",
    "train_filenames = pd.DataFrame(np.array(train_filenames).reshape((len(train_filenames),1)))\n",
    "# Convert labels list to DataFrame column for concatenation\n",
    "train_labels = pd.DataFrame(mat3['labels'])\n",
    "# Concatenate filenames and labels\n",
    "train_file_label = pd.concat((train_labels,train_filenames),axis=1)\n",
    "# Add column names to concatenated dataframe\n",
    "train_file_label.columns=['label','filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MahtExq9dS-a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>n02085620-Chihuahua/n02085620_5927.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>n02085620-Chihuahua/n02085620_4441.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>n02085620-Chihuahua/n02085620_1502.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>n02085620-Chihuahua/n02085620_1916.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>n02085620-Chihuahua/n02085620_13151.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>120</td>\n",
       "      <td>n02116738-African_hunting_dog/n02116738_10614.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>120</td>\n",
       "      <td>n02116738-African_hunting_dog/n02116738_9282.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>120</td>\n",
       "      <td>n02116738-African_hunting_dog/n02116738_6754.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>120</td>\n",
       "      <td>n02116738-African_hunting_dog/n02116738_9333.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>120</td>\n",
       "      <td>n02116738-African_hunting_dog/n02116738_2503.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           filename\n",
       "0          1             n02085620-Chihuahua/n02085620_5927.jpg\n",
       "1          1             n02085620-Chihuahua/n02085620_4441.jpg\n",
       "2          1             n02085620-Chihuahua/n02085620_1502.jpg\n",
       "3          1             n02085620-Chihuahua/n02085620_1916.jpg\n",
       "4          1            n02085620-Chihuahua/n02085620_13151.jpg\n",
       "...      ...                                                ...\n",
       "11995    120  n02116738-African_hunting_dog/n02116738_10614.jpg\n",
       "11996    120   n02116738-African_hunting_dog/n02116738_9282.jpg\n",
       "11997    120   n02116738-African_hunting_dog/n02116738_6754.jpg\n",
       "11998    120   n02116738-African_hunting_dog/n02116738_9333.jpg\n",
       "11999    120   n02116738-African_hunting_dog/n02116738_2503.jpg\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "78iusQfAzLIa"
   },
   "outputs": [],
   "source": [
    "### Keeping this code here in case the image stuff doesn't work out, but it's tough to use. The labels in y, y_test, and y_train are in the same order as the \n",
    "### feature data in X_train and X_test, but I don't really understand what that \"feature data\" is. Each image is described as a 5,073-dimensional vector \n",
    "### (X_train is 12000x5073 and X_test is 8580x5073). But if things get bleak, we can just use this code and start running models using it.\n",
    "\n",
    "# Save filepaths that contain feature data for training and test sets\n",
    "#file4 = '/content/gdrive/My Drive/train_data.mat'\n",
    "#file5 = '/content/gdrive/My Drive/test_data.mat'\n",
    "\n",
    "# Read in training and test set feature data\n",
    "#mat4 = scipy.io.loadmat(file4)\n",
    "#mat5 = scipy.io.loadmat(file5)\n",
    "\n",
    "# Extract X_train and X_test from dict\n",
    "#X_train = mat4['train_fg_data']\n",
    "#X_test = mat5['test_fg_data']\n",
    "\n",
    "# Extract y_train and y_test from dict\n",
    "#y = mat1['labels']\n",
    "#y_train = mat3['labels']\n",
    "#y_test = mat2['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6V65U5Ay5XX8"
   },
   "outputs": [],
   "source": [
    "# Save all image arrays as dataframe\n",
    "a = pd.DataFrame(data_list)\n",
    "# Rename column of image arrays\n",
    "a = a.rename(columns={0:'data'})\n",
    "# Add filenames, which were acquired in sequence during original for loop, as column in dataframe\n",
    "a['filename'] = file_string_list\n",
    "# Create dataframe of training image arrays\n",
    "train_file = train_file_label.merge(a, on='filename', how='inner')\n",
    "# Create dataframe of test image arrays\n",
    "test_file = test_file_label.merge(a, on='filename', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "o06HNeeqArVk"
   },
   "outputs": [],
   "source": [
    "# Save list of training set labels\n",
    "y_train_numbers = train_file.label\n",
    "# Define array that will hold training set labels in softmax form\n",
    "y_train = np.zeros((y_train_numbers.shape[0],120))\n",
    "# For each image...\n",
    "for i in range(y_train_numbers.shape[0]):\n",
    "    # Flip the appropriate column's entry (each column represents a different breed) to 1\n",
    "    y_train[i,y_train_numbers[i]-1] = 1\n",
    "# Save list of test set labels\n",
    "y_test_numbers = test_file.label\n",
    "# Define array that will hold test set labels in softmax form\n",
    "y_test = np.zeros((y_test_numbers.shape[0],120))\n",
    "# For each image...\n",
    "for i in range(y_test_numbers.shape[0]):\n",
    "    # Flip the appropriate column's entry (each column represents a different breed) to 1\n",
    "    y_test[i,y_test_numbers[i]-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_bK-ATtyA6Tk"
   },
   "outputs": [],
   "source": [
    "# Save series of image arrays as list\n",
    "X_train = list(train_file.data)\n",
    "# Remove empty 4th dimension from 7904th image\n",
    "X_train[7904] = X_train[7904][:,:,0:3]\n",
    "# Convert training set to numpy array and normalize variables\n",
    "X_train = np.array(X_train).astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test set to numpy array and normalize variables\n",
    "X_test = np.array(list(test_file.data)).astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can use this format to show an image. This current code shows the blank 4th dimension, but you could change\n",
    "# the 3 to 0, 1, or 2 to see a vague image of the collie\n",
    "#image3=Image.fromarray(X_train[7904][:,:,3])\n",
    "#image3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## At this point, the image data should be formatted properly for entry into a neural network. I've just been\n",
    "# using my autoencoder from the homework to check functionality of the data format; you can delete below this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model is very standard - 3x3 kernels throughout, strides of 1 in both axes throughout, ReLU activation functions, padding that preserves dimensions, and a neuron sequence of 32-32-64-64-128-128-32-16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "_bK-ATtyA6Tk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_98 (Conv2D)           (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 200, 200, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 25, 25, 32)        36896     \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 20000)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 120)               2400120   \n",
      "=================================================================\n",
      "Total params: 2,724,024\n",
      "Trainable params: 2,724,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Start with empty sequential model\n",
    "model = Sequential()\n",
    "# Add pair of 32-neuron hidden layers with ReLU activation function, 3x3 kernel, stride length of 1 in both dimensions, and padding that maintains 32x32 shape\n",
    "model.add(layers.Conv2D(32, (3,3), strides=(1,1), activation='relu', padding='same', input_shape=(200, 200, 3)))\n",
    "model.add(layers.Conv2D(32, (3,3), strides=(1,1), activation='relu', padding='same'))\n",
    "# Max pooling of 2x2 sections to get dimensionality of each image down to 16x16\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# Add pair of 64-neuron hidden layers with ReLU activation function, 3x3 kernel, stride length of 1 in both dimensions, and padding that maintains 16x16 shape\n",
    "model.add(layers.Conv2D(64, (3,3), strides=(1,1), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(64, (3,3), strides=(1,1), activation='relu', padding='same'))\n",
    "# Max pooling of 2x2 sections to get dimensionality of each image down to 8x8\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# Add pair of 128-neuron hidden layers with ReLU activation function, 3x3 kernel, stride length of 1 in both dimensions, and padding that maintains 8x8 shape\n",
    "model.add(layers.Conv2D(128, (3,3), strides=(1,1), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(128, (3, 3), strides=(1,1), activation='relu', padding='same'))\n",
    "# Max pooling of 2x2 sections to get dimensionality of each image down to 4x4\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# Flatten 4x4x128 network into \n",
    "model.add(layers.Conv2D(32, (3, 3), strides=(1,1), activation='relu', padding='same'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(120, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "5SWB-YMpA9YZ",
    "outputId": "f187824d-4f75-4054-89f3-46fddc0ada8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81/188 [===========>..................] - ETA: 18:36 - loss: 4.7891 - accuracy: 0.0064"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-32d184eb638d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model.fit(X_train, y_train, epochs=1, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second model only changes the kernel size to 6x6; otherwise, we keep strides of 1 in both axes throughout, ReLU activation functions, padding that preserves dimensions, and a neuron sequence of 32-32-64-64-128-128-32-16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-mDOFvKRkfC"
   },
   "outputs": [],
   "source": [
    "# Start with empty sequential model\n",
    "model2 = Sequential()\n",
    "# Add pair of 32-neuron hidden layers with ReLU activation function, 3x3 kernel, stride length of 1 in both dimensions, and padding that maintains 32x32 shape\n",
    "model2.add(layers.Conv2D(32, (6,6), strides=(1,1), activation='relu', padding='same', input_shape=(200, 200, 3)))\n",
    "model2.add(layers.Conv2D(32, (6,6), strides=(1,1), activation='relu', padding='same'))\n",
    "# Max pooling of 2x2 sections to get dimensionality of each image down to 16x16\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "# Add pair of 64-neuron hidden layers with ReLU activation function, 3x3 kernel, stride length of 1 in both dimensions, and padding that maintains 16x16 shape\n",
    "model2.add(layers.Conv2D(64, (6,6), strides=(1,1), activation='relu', padding='same'))\n",
    "model2.add(layers.Conv2D(64, (6,6), strides=(1,1), activation='relu', padding='same'))\n",
    "# Max pooling of 2x2 sections to get dimensionality of each image down to 8x8\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "# Add pair of 128-neuron hidden layers with ReLU activation function, 3x3 kernel, stride length of 1 in both dimensions, and padding that maintains 8x8 shape\n",
    "model2.add(layers.Conv2D(128, (6,6), strides=(1,1), activation='relu', padding='same'))\n",
    "model2.add(layers.Conv2D(128, (6,6), strides=(1,1), activation='relu', padding='same'))\n",
    "# Max pooling of 2x2 sections to get dimensionality of each image down to 4x4\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "# Flatten 4x4x128 network into \n",
    "model2.add(layers.Conv2D(32, (6,6), strides=(1,1), activation='relu', padding='same'))\n",
    "#model2.add(layers.Conv2D(16, (6,6), strides=(1,1), activation='relu', padding='same'))\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(120, activation='softmax'))\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.fit(X_train, y_train, epochs=1, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also try some transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 6, 6, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_8 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 120)               61560     \n",
      "=================================================================\n",
      "Total params: 14,776,248\n",
      "Trainable params: 61,560\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import library that contains VGG weights\n",
    "\n",
    "# Construct variable that uses VGG weights for 32x32x3 input image\n",
    "conv_base = VGG16(weights=\"imagenet\",include_top=False,input_shape=(200,200,3))\n",
    "# Define transfer learning model\n",
    "model3 = Sequential()\n",
    "# Freeze VGG weights\n",
    "conv_base.trainable=False\n",
    "# Add VGG weights to model\n",
    "model3.add(conv_base)\n",
    "# Add final dense 10-element layer that will contain softmax probabilities\n",
    "model3.add(layers.GlobalMaxPool2D())\n",
    "model3.add(layers.Dense(120,activation='softmax'))\n",
    "# Compile model\n",
    "model3.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
    "# Print model summary\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 6180s 8s/step - loss: 4.4205 - categorical_accuracy: 0.0653 - val_loss: 3.8695 - val_categorical_accuracy: 0.1432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f93e55a2790>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train, epochs=1, batch_size=16, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 24s 0us/step\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Functional)        (None, 7, 7, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_6 (Glob (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 120)               245880    \n",
      "=================================================================\n",
      "Total params: 21,107,360\n",
      "Trainable params: 245,880\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import library that contains VGG weights\n",
    "\n",
    "# Construct variable that uses VGG weights for 32x32x3 input image\n",
    "conv_base = Xception(weights=\"imagenet\",include_top=False,input_shape=(200,200,3))\n",
    "# Define transfer learning model\n",
    "model4 = Sequential()\n",
    "# Freeze VGG weights\n",
    "conv_base.trainable=False\n",
    "# Add VGG weights to model\n",
    "model4.add(conv_base)\n",
    "# Add final dense 10-element layer that will contain softmax probabilities\n",
    "model4.add(layers.GlobalMaxPool2D())\n",
    "model4.add(layers.Dense(120,activation='softmax'))\n",
    "# Compile model\n",
    "model4.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
    "# Print model summary\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 2149s 6s/step - loss: 1.5205 - categorical_accuracy: 0.6622 - val_loss: 1.2504 - val_categorical_accuracy: 0.7270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f972ad13ca0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94674944/94668760 [==============================] - 158s 2us/step\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Functional)      (None, 7, 7, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_7 (Glob (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 120)               245880    \n",
      "=================================================================\n",
      "Total params: 23,810,680\n",
      "Trainable params: 245,880\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import library that contains VGG weights\n",
    "\n",
    "# Construct variable that uses VGG weights for 32x32x3 input image\n",
    "conv_base = ResNet50V2(weights=\"imagenet\",include_top=False,input_shape=(200,200,3))\n",
    "# Define transfer learning model\n",
    "model5 = Sequential()\n",
    "# Freeze VGG weights\n",
    "conv_base.trainable=False\n",
    "# Add VGG weights to model\n",
    "model5.add(conv_base)\n",
    "# Add final dense 10-element layer that will contain softmax probabilities\n",
    "model5.add(layers.GlobalMaxPool2D())\n",
    "model5.add(layers.Dense(120,activation='softmax'))\n",
    "# Compile model\n",
    "model5.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
    "# Print model summary\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1590s 4s/step - loss: 9.2001 - categorical_accuracy: 0.4018 - val_loss: 5.9429 - val_categorical_accuracy: 0.5467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f93ce37b640>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15/375 [>.............................] - ETA: 5:02 - loss: 4.7943 - accuracy: 0.0021"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-e9ec1dddb95a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel_little\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#model_little.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel_little\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model_little = Sequential()\n",
    "#model_little.add(layers.Conv2D(32, (5,5), strides=(1,1), activation='relu', padding='same', input_shape=(200, 200, 3)))\n",
    "#model_little.add(layers.MaxPooling2D((4, 4)))\n",
    "#model_little.add(layers.Conv2D(16, (5,5), strides=(1,1), activation='relu', padding='same'))\n",
    "#model_little.add(layers.MaxPooling2D((4, 4)))\n",
    "#model_little.add(layers.Conv2D(8, (3,3), strides=(1,1), activation='relu', padding='same'))\n",
    "#model_little.add(layers.MaxPooling2D((2, 2)))\n",
    "#model_little.add(layers.Conv2D(4, (3,3), strides=(1,1), activation='relu', padding='same'))\n",
    "#model_little.add(layers.MaxPooling2D((2, 2)))\n",
    "#model_little.add(layers.Flatten())\n",
    "#model_little.add(layers.Dense(120, activation='softmax'))\n",
    "#model_little.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model_little.summary()\n",
    "#model_little.fit(X_train, y_train, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an attempt at ensemble learning with simple models. No dice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 384s 1s/step - loss: 4.7889 - accuracy: 0.0052\n",
      ">Saved models/model_1.h5\n",
      "375/375 [==============================] - 359s 958ms/step - loss: 4.7888 - accuracy: 0.0061\n",
      ">Saved models/model_2.h5\n",
      "375/375 [==============================] - 386s 1s/step - loss: 4.7804 - accuracy: 0.0098\n",
      ">Saved models/model_3.h5\n",
      "375/375 [==============================] - 361s 963ms/step - loss: 4.7886 - accuracy: 0.0060\n",
      ">Saved models/model_4.h5\n",
      "375/375 [==============================] - 380s 1s/step - loss: 4.7833 - accuracy: 0.0077\n",
      ">Saved models/model_5.h5\n"
     ]
    }
   ],
   "source": [
    "def fit_model(trainX, trainy):\n",
    "    # define model\n",
    "    model_little = Sequential()\n",
    "    model_little.add(layers.Conv2D(32, (5,5), strides=(1,1), activation='relu', padding='same', input_shape=(200, 200, 3)))\n",
    "    model_little.add(layers.MaxPooling2D((4, 4)))\n",
    "    model_little.add(layers.Conv2D(16, (5,5), strides=(1,1), activation='relu', padding='same'))\n",
    "    model_little.add(layers.MaxPooling2D((2, 2)))\n",
    "    model_little.add(layers.Conv2D(8, (3,3), strides=(1,1), activation='relu', padding='same'))\n",
    "    model_little.add(layers.MaxPooling2D((2, 2)))\n",
    "    model_little.add(layers.Conv2D(4, (3,3), strides=(1,1), activation='relu', padding='same'))\n",
    "    model_little.add(layers.MaxPooling2D((2, 2)))\n",
    "    model_little.add(layers.Flatten())\n",
    "    model_little.add(layers.Dense(120, activation='softmax'))\n",
    "    model_little.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_little.fit(X_train, y_train, epochs=1)\n",
    "    return model_little\n",
    "\n",
    "\n",
    "#makedirs('models')\n",
    "# fit and save models\n",
    "n_members = 5\n",
    "for i in range(n_members):\n",
    "    # fit model\n",
    "    model = fit_model(X_train, y_train)\n",
    "    # save model\n",
    "    filename = 'models/model_' + str(i + 1) + '.h5'\n",
    "    model.save(filename)\n",
    "    print('>Saved %s' % filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we get serious and do an ensemble model where each of the submodels is a transfer learning model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Xception model\n",
    "model4.save('models/model_4.h5')\n",
    "# Save ResNet model\n",
    "model5.save('models/model_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop is here in case we want to make a loop of identical simple models in the future. Chris, maybe your computer\n",
    "# is powerful enough to make this work.\n",
    "\n",
    "#def load_all_models(n_models):\n",
    "#    all_models = list()\n",
    "#    for i in range(n_models):\n",
    "#        # define filename for this ensemble\n",
    "#        filename = 'models/model_' + str(i + 1) + '.h5'\n",
    "#        # load model from file\n",
    "#        model = load_model(filename)\n",
    "#        # add to list of members\n",
    "#        all_models.append(model)\n",
    "#        print('>loaded %s' % filename)\n",
    "#    return all_models\n",
    "#\n",
    "#n_members = 5\n",
    "#members = load_all_models(n_members)\n",
    "#print('Loaded %d models' % len(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 941s 3s/step - loss: 1.2504 - categorical_accuracy: 0.7270\n",
      "269/269 [==============================] - 657s 2s/step - loss: 5.9429 - categorical_accuracy: 0.5467\n",
      "Xception accuracy: [1.2504279613494873, 0.727039635181427]\n",
      "ResNet accuracy: [5.942904472351074, 0.5467365980148315]\n"
     ]
    }
   ],
   "source": [
    "# Define empty list that will hold sub-models\n",
    "all_tran_models = list()\n",
    "# Load Xception model\n",
    "model4 = load_model('models/model_4.h5')\n",
    "# Add Xception model to list\n",
    "all_tran_models.append(model4)\n",
    "# Load ResNet model\n",
    "model5 = load_model('models/model_5.h5')\n",
    "# Add ResNet model to list\n",
    "all_tran_models.append(model5)\n",
    "\n",
    "# Evaluate and print accuracy of Xception and ResNet models in isolation (for comparison against ensemble accuracy)\n",
    "model4_acc = model4.evaluate(X_test,y_test)\n",
    "model5_acc = model5.evaluate(X_test,y_test)\n",
    "print('Xception accuracy:',model4_acc)\n",
    "print('ResNet accuracy:',model5_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 1738s 6s/step - loss: 3.8695 - categorical_accuracy: 0.1432\n",
      "VGG accuracy: [3.8695106506347656, 0.1432400941848755]\n"
     ]
    }
   ],
   "source": [
    "# Save VGG model to file\n",
    "model3.save('models/model_3.h5')\n",
    "# Load VGG model from disk\n",
    "model3 = load_model('models/model_3.h5')\n",
    "# Add VGG model to list of models\n",
    "all_tran_models.append(model3)\n",
    "# Evaluate and print performance of VGG model in isolation\n",
    "model3_acc = model3.evaluate(X_test,y_test)\n",
    "print('VGG accuracy:',model3_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Again, code if we want to large number of simple, identical models later\n",
    "\n",
    "#for model in members:\n",
    "#    y_test_enc = to_categorical(y_test)\n",
    "#    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "#    print('Model Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 848s 3s/step\n",
      "269/269 [==============================] - 613s 2s/step\n",
      "269/269 [==============================] - 1918s 7s/step\n",
      "230/269 [========================>.....] - ETA: 2:30"
     ]
    }
   ],
   "source": [
    "## Function creates multiple copies of X for evaluation\n",
    "def stacked_dataset(members, inputX):\n",
    "    # Define structure that will hold all predictions\n",
    "    stackX = None\n",
    "    # For each model contributing to ensemble...\n",
    "    for model in members:\n",
    "        # Make predictions using this model\n",
    "        yhat = model.predict(inputX,verbose=1)\n",
    "        # If stack is empty, start stack with predictions from this model\n",
    "        if stackX is None:\n",
    "            stackX = yhat\n",
    "        # If stack is not empty, add predictions from this model to stack\n",
    "        else:\n",
    "            stackX = dstack((stackX, yhat))\n",
    "    # Flatten predictions of all models into [observations, models x probabilities] shape\n",
    "    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
    "    # Return flattened predictions\n",
    "    return stackX\n",
    "\n",
    "# Define function that fits ensemble model\n",
    "def fit_stacked_model(members, inputX, inputy):\n",
    "    # Create dataset of multiple copies of datset for use in ensemble model\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    # Fit ensemble model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(stackedX, inputy)\n",
    "    return model\n",
    "\n",
    "# Use 2 aforementioned functions to create dataset shape to fit ensemble model, and then fit ensemble model\n",
    "model_ensemble = fit_stacked_model(all_tran_models, X_test, np.array(y_test_numbers))\n",
    "\n",
    "## Define function that makes predictions based on fit ensemble model\n",
    "def stacked_prediction(members, model, inputX):\n",
    "    # Create stacked copies of dataset\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    # Make a prediction on stacked, copied dataset using ensemble model\n",
    "    yhat = model.predict(stackedX,verbose=1)\n",
    "    return yhat\n",
    "\n",
    "\n",
    "# Make predictions using fit ensemble model\n",
    "yhat = stacked_prediction(all_tran_models, model_ensemble, X_test)\n",
    "# Print accuracy of ensemble model\n",
    "acc = accuracy_score(np.array(y_test_numbers), yhat)\n",
    "print('Stacked Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "590Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
